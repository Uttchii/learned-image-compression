{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "!pip install compressai\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from compressai.zoo import mbt2018\n",
        "\n",
        "print(\"âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = mbt2018(quality=3, pretrained=True, progress=True)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"âœ… è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº† (ãƒ‡ãƒã‚¤ã‚¹: {device})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆç”»åƒã‚’ä½œæˆ\n",
        "test_image = torch.zeros(1, 3, 256, 256).to(device)\n",
        "test_image[0, 0, :128, :128] = 1.0  # å·¦ä¸Š: èµ¤\n",
        "test_image[0, 1, :128, 128:] = 1.0  # å³ä¸Š: ç·‘\n",
        "test_image[0, 2, 128:, :128] = 1.0  # å·¦ä¸‹: é’\n",
        "test_image[0, :, 128:, 128:] = 0.5  # å³ä¸‹: ã‚°ãƒ¬ãƒ¼\n",
        "\n",
        "print(\"âœ… ãƒ†ã‚¹ãƒˆç”»åƒä½œæˆå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç”»åƒåœ§ç¸®ãƒ»å±•é–‹ã®å®Ÿè¡Œ\n",
        "with torch.no_grad():\n",
        "    # åœ§ç¸®\n",
        "    compressed = model.compress(test_image)\n",
        "    # å±•é–‹\n",
        "    decompressed = model.decompress(compressed[\"strings\"], compressed[\"shape\"])\n",
        "    reconstructed = decompressed[\"x_hat\"]\n",
        "\n",
        "print(\"âœ… åœ§ç¸®ãƒ»å±•é–‹å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ æœ€çµ‚çµæœã®è¡¨ç¤º\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# å…ƒç”»åƒ\n",
        "original_img = test_image[0].cpu().permute(1, 2, 0).clamp(0, 1)\n",
        "axes[0].imshow(original_img)\n",
        "axes[0].set_title('å…ƒç”»åƒ', fontsize=16, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# åœ§ç¸®ãƒ»å¾©å…ƒå¾Œã®ç”»åƒ\n",
        "reconstructed_img = reconstructed[0].cpu().permute(1, 2, 0).clamp(0, 1)\n",
        "axes[1].imshow(reconstructed_img)\n",
        "axes[1].set_title('åœ§ç¸®ãƒ»å¾©å…ƒå¾Œ', fontsize=16, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# åœ§ç¸®åŠ¹æœã®æ•°å€¤\n",
        "original_size = test_image.numel() * 8  # bits\n",
        "compressed_size = len(compressed['strings'][0]) * 8  # bits\n",
        "compression_ratio = original_size / compressed_size\n",
        "mse = torch.mean((test_image - reconstructed) ** 2).item()\n",
        "psnr = -10 * torch.log10(torch.tensor(mse))\n",
        "\n",
        "print(\"\\nğŸ¯ === æœ€çµ‚çµæœ ===\")\n",
        "print(f\"ğŸ“Š åœ§ç¸®ç‡: {compression_ratio:.1f}å€\")\n",
        "print(f\"ğŸ“ˆ PSNR: {psnr:.1f} dB\")\n",
        "print(f\"ğŸ’¾ å…ƒã‚µã‚¤ã‚º: {original_size//8:,} bytes\")\n",
        "print(f\"ğŸ—œï¸ åœ§ç¸®å¾Œ: {len(compressed['strings'][0]):,} bytes\")\n",
        "print(\"\\nâœ¨ å­¦ç¿’ãƒ™ãƒ¼ã‚¹ç”»åƒåœ§ç¸®ã®æˆåŠŸï¼\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
