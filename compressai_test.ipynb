{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uttchii/learned-image-compression/blob/main/compressai_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74cpmkTQq1zD",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# è¨“ç·´æ¸ˆã¿ç”»åƒåœ§ç¸®ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ - CompressAIç‰ˆ\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€**è¨“ç·´æ¸ˆã¿ã®**ç”»åƒåœ§ç¸®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
        "- **è«–æ–‡**: \"Joint Autoregressive and Hierarchical Priors for Learned Image Compression\" (NeurIPS 2018)\n",
        "- **ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**: CompressAI - è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä»˜ã\n",
        "- **å®Ÿè¡Œç’°å¢ƒ**: Google Colabï¼ˆGPUæ¨å¥¨ï¼‰\n",
        "\n",
        "**ç‰¹å¾´**:\n",
        "âœ… å®Ÿéš›ã«ç”»åƒã‚’åœ§ç¸®ãƒ»å±•é–‹å¯èƒ½\n",
        "âœ… å“è³ªãƒ¬ãƒ™ãƒ«èª¿æ•´å¯èƒ½ï¼ˆ1-8ï¼‰\n",
        "âœ… å®Ÿç”¨çš„ãªæ€§èƒ½è©•ä¾¡\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzyJayn7q1zE"
      },
      "outputs": [],
      "source": [
        "# 1. CompressAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install compressai\n",
        "\n",
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torchvision import transforms\n",
        "\n",
        "print(\"âœ“ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-lns-qDq1zE"
      },
      "outputs": [],
      "source": [
        "# 2. ç’°å¢ƒç¢ºèªã¨ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
        "print(\"=== ç’°å¢ƒç¢ºèª ===\")\n",
        "print(f\"PyTorch ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {torch.__version__}\")\n",
        "print(f\"torchvision ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {torchvision.__version__}\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU ãƒ‡ãƒã‚¤ã‚¹: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU ãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"CPU ã§å®Ÿè¡Œã—ã¾ã™ï¼ˆGPUã®æ–¹ãŒé«˜é€Ÿã§ã™ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNkyFiodq1zE"
      },
      "outputs": [],
      "source": [
        "# 3. è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
        "from compressai.zoo import mbt2018\n",
        "\n",
        "print(\"=== è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ===\")\n",
        "\n",
        "# å“è³ªãƒ¬ãƒ™ãƒ«é¸æŠ (1: ä½å“è³ª/ä½ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆ, 8: é«˜å“è³ª/é«˜ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆ)\n",
        "quality_level = 3\n",
        "print(f\"å“è³ªãƒ¬ãƒ™ãƒ«: {quality_level}/8\")\n",
        "\n",
        "# è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã¯é‡ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰\n",
        "print(\"è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "model = mbt2018(quality=quality_level, pretrained=True, progress=True)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"âœ“ è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿å®Œäº†ï¼\")\n",
        "print(f\"ãƒ¢ãƒ‡ãƒ«: {model.__class__.__name__}\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬æƒ…å ±\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gig9HsK7q1zE"
      },
      "outputs": [],
      "source": [
        "# 4. ãƒ†ã‚¹ãƒˆç”»åƒã®ä½œæˆã¨åœ§ç¸®ãƒ»å±•é–‹\n",
        "print(\"=== ãƒ†ã‚¹ãƒˆç”»åƒã§ã®åœ§ç¸®ãƒ»å±•é–‹ãƒ†ã‚¹ãƒˆ ===\")\n",
        "\n",
        "# ã‚«ãƒ©ãƒ•ãƒ«ãªãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆ\n",
        "def create_test_image():\n",
        "    \"\"\"ãƒ†ã‚¹ãƒˆç”¨ã®ã‚«ãƒ©ãƒ•ãƒ«ãªç”»åƒã‚’ä½œæˆ\"\"\"\n",
        "    test_image = torch.zeros(1, 3, 256, 256)\n",
        "\n",
        "    # 4ã¤ã®è‰²ä»˜ãé ˜åŸŸã‚’ä½œæˆ\n",
        "    test_image[0, 0, :128, :128] = 1.0      # å·¦ä¸Š: èµ¤\n",
        "    test_image[0, 1, :128, 128:] = 1.0      # å³ä¸Š: ç·‘\n",
        "    test_image[0, 2, 128:, :128] = 1.0      # å·¦ä¸‹: é’\n",
        "    test_image[0, :, 128:, 128:] = 0.5      # å³ä¸‹: ã‚°ãƒ¬ãƒ¼\n",
        "\n",
        "    # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åŠ¹æœã‚’è¿½åŠ \n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            if 100 < i < 156 and 100 < j < 156:\n",
        "                # ä¸­å¤®éƒ¨åˆ†ã«ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "                test_image[0, :, i, j] = (i - 100) / 56.0\n",
        "\n",
        "    return test_image\n",
        "\n",
        "test_image = create_test_image().to(device)\n",
        "print(f\"ãƒ†ã‚¹ãƒˆç”»åƒã‚µã‚¤ã‚º: {test_image.shape}\")\n",
        "\n",
        "# åœ§ç¸®ãƒ»å±•é–‹ã®å®Ÿè¡Œ\n",
        "print(\"åœ§ç¸®ãƒ»å±•é–‹ã‚’å®Ÿè¡Œä¸­...\")\n",
        "with torch.no_grad():\n",
        "    # åœ§ç¸®\n",
        "    compressed = model.compress(test_image)\n",
        "    print(f\"åœ§ç¸®å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed['strings'][0])} bytes\")\n",
        "\n",
        "    # å±•é–‹\n",
        "    decompressed = model.decompress(compressed[\"strings\"], compressed[\"shape\"])\n",
        "    reconstructed = decompressed[\"x_hat\"]\n",
        "\n",
        "print(f\"å¾©å…ƒç”»åƒã‚µã‚¤ã‚º: {reconstructed.shape}\")\n",
        "print(\"âœ“ åœ§ç¸®ãƒ»å±•é–‹ãŒæˆåŠŸã—ã¾ã—ãŸï¼\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTplQ8ATq1zE"
      },
      "outputs": [],
      "source": [
        "# 5. çµæœã®å¯è¦–åŒ–ã¨å“è³ªè©•ä¾¡\n",
        "print(\"=== åœ§ç¸®çµæœã®å¯è¦–åŒ– ===\")\n",
        "\n",
        "# åœ§ç¸®å‰å¾Œã®æ¯”è¼ƒ\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# å…ƒç”»åƒ\n",
        "original_img = test_image[0].cpu().permute(1, 2, 0).clamp(0, 1)\n",
        "axes[0].imshow(original_img)\n",
        "axes[0].set_title('å…ƒç”»åƒ', fontsize=14, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# å¾©å…ƒç”»åƒ\n",
        "reconstructed_img = reconstructed[0].cpu().permute(1, 2, 0).clamp(0, 1)\n",
        "axes[1].imshow(reconstructed_img)\n",
        "axes[1].set_title('å¾©å…ƒç”»åƒï¼ˆè¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼‰', fontsize=14, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "# å·®åˆ†ç”»åƒ\n",
        "diff = torch.abs(test_image[0] - reconstructed[0]).cpu().permute(1, 2, 0)\n",
        "diff_normalized = diff / (diff.max() + 1e-8)  # æ­£è¦åŒ–\n",
        "axes[2].imshow(diff_normalized)\n",
        "axes[2].set_title('å·®åˆ†ç”»åƒï¼ˆæ˜ã‚‹ã„éƒ¨åˆ†=å·®ãŒå¤§ãã„ï¼‰', fontsize=14, fontweight='bold')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# å“è³ªè©•ä¾¡\n",
        "print(\"=== å“è³ªè©•ä¾¡ ===\")\n",
        "mse = torch.mean((test_image - reconstructed) ** 2).item()\n",
        "psnr = -10 * torch.log10(torch.tensor(mse)) if mse > 0 else float('inf')\n",
        "\n",
        "# ãƒ“ãƒƒãƒˆç‡è¨ˆç®— (æ¦‚ç®—)\n",
        "original_size = test_image.numel() * 8  # 8 bits per pixel (RGB)\n",
        "compressed_size = len(compressed['strings'][0]) * 8  # bytes to bits\n",
        "compression_ratio = original_size / compressed_size\n",
        "bits_per_pixel = compressed_size / (256 * 256)\n",
        "\n",
        "print(f\"MSE: {mse:.6f}\")\n",
        "print(f\"PSNR: {psnr:.2f} dB\")\n",
        "print(f\"åœ§ç¸®ç‡: {compression_ratio:.1f}x\")\n",
        "print(f\"ãƒ“ãƒƒãƒˆ/ãƒ”ã‚¯ã‚»ãƒ«: {bits_per_pixel:.3f} bpp\")\n",
        "print(f\"å…ƒãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {original_size // 8:,} bytes\")\n",
        "print(f\"åœ§ç¸®å¾Œã‚µã‚¤ã‚º: {len(compressed['strings'][0]):,} bytes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BHJwYDtq1zF"
      },
      "outputs": [],
      "source": [
        "# 6. å®Ÿéš›ã®ç”»åƒã§ã®è©¦è¡Œ\n",
        "print(\"=== å®Ÿéš›ã®ç”»åƒã§ã®åœ§ç¸®ãƒ†ã‚¹ãƒˆ ===\")\n",
        "\n",
        "# ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "def download_sample_image():\n",
        "    \"\"\"ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\"\"\"\n",
        "    try:\n",
        "        # Wikipedia ã®é«˜å“è³ªãªç”»åƒã‚’ä½¿ç”¨\n",
        "        url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Vd-Orig.png/256px-Vd-Orig.png\"\n",
        "        response = requests.get(url, timeout=10)\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "        print(\"âœ“ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ\")\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "        print(\"ä»£æ›¿ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™...\")\n",
        "        # ä»£æ›¿ç”»åƒã‚’ç”Ÿæˆ\n",
        "        img = Image.new('RGB', (256, 256), color='white')\n",
        "        return img\n",
        "\n",
        "# ç”»åƒã®å‰å‡¦ç†\n",
        "def preprocess_image(img):\n",
        "    \"\"\"ç”»åƒã‚’å‰å‡¦ç†ã—ã¦ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›\"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    return transform(img).unsqueeze(0)\n",
        "\n",
        "# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã§ã®å®Ÿé¨“\n",
        "sample_img = download_sample_image()\n",
        "real_image = preprocess_image(sample_img).to(device)\n",
        "print(f\"å®Ÿç”»åƒã‚µã‚¤ã‚º: {real_image.shape}\")\n",
        "\n",
        "# åœ§ç¸®ãƒ»å±•é–‹\n",
        "print(\"å®Ÿç”»åƒã‚’åœ§ç¸®ãƒ»å±•é–‹ä¸­...\")\n",
        "with torch.no_grad():\n",
        "    compressed_real = model.compress(real_image)\n",
        "    decompressed_real = model.decompress(compressed_real[\"strings\"], compressed_real[\"shape\"])\n",
        "    reconstructed_real = decompressed_real[\"x_hat\"]\n",
        "\n",
        "print(\"âœ“ å®Ÿç”»åƒã§ã®åœ§ç¸®ãƒ»å±•é–‹ãŒæˆåŠŸã—ã¾ã—ãŸï¼\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTjyDAslq1zF"
      },
      "outputs": [],
      "source": [
        "# 7. å®Ÿç”»åƒçµæœã®æ¯”è¼ƒ\n",
        "print(\"=== å®Ÿç”»åƒã®åœ§ç¸®çµæœ ===\")\n",
        "\n",
        "# æ¯”è¼ƒè¡¨ç¤º\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# å…ƒã®å®Ÿç”»åƒ\n",
        "real_original = real_image[0].cpu().permute(1, 2, 0).clamp(0, 1)\n",
        "axes[0].imshow(real_original)\n",
        "axes[0].set_title('å…ƒã®å®Ÿç”»åƒ', fontsize=14, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# å¾©å…ƒã•ã‚ŒãŸå®Ÿç”»åƒ\n",
        "real_reconstructed = reconstructed_real[0].cpu().permute(1, 2, 0).clamp(0, 1)\n",
        "axes[1].imshow(real_reconstructed)\n",
        "axes[1].set_title('åœ§ç¸®ãƒ»å¾©å…ƒå¾Œ', fontsize=14, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "# å·®åˆ†\n",
        "real_diff = torch.abs(real_image[0] - reconstructed_real[0]).cpu().permute(1, 2, 0)\n",
        "real_diff_normalized = real_diff / (real_diff.max() + 1e-8)\n",
        "axes[2].imshow(real_diff_normalized)\n",
        "axes[2].set_title('å·®åˆ†ç”»åƒ', fontsize=14, fontweight='bold')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# å®Ÿç”»åƒã§ã®å“è³ªè©•ä¾¡\n",
        "print(\"=== å®Ÿç”»åƒã§ã®å“è³ªè©•ä¾¡ ===\")\n",
        "real_mse = torch.mean((real_image - reconstructed_real) ** 2).item()\n",
        "real_psnr = -10 * torch.log10(torch.tensor(real_mse)) if real_mse > 0 else float('inf')\n",
        "\n",
        "real_original_size = real_image.numel() * 8\n",
        "real_compressed_size = len(compressed_real['strings'][0]) * 8\n",
        "real_compression_ratio = real_original_size / real_compressed_size\n",
        "real_bpp = real_compressed_size / (256 * 256)\n",
        "\n",
        "print(f\"å®Ÿç”»åƒ MSE: {real_mse:.6f}\")\n",
        "print(f\"å®Ÿç”»åƒ PSNR: {real_psnr:.2f} dB\")\n",
        "print(f\"å®Ÿç”»åƒ åœ§ç¸®ç‡: {real_compression_ratio:.1f}x\")\n",
        "print(f\"å®Ÿç”»åƒ ãƒ“ãƒƒãƒˆ/ãƒ”ã‚¯ã‚»ãƒ«: {real_bpp:.3f} bpp\")\n",
        "print(f\"å®Ÿç”»åƒ åœ§ç¸®å¾Œã‚µã‚¤ã‚º: {len(compressed_real['strings'][0]):,} bytes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj11P4ZWq1zF"
      },
      "outputs": [],
      "source": [
        "# 8. å“è³ªãƒ¬ãƒ™ãƒ«æ¯”è¼ƒï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
        "print(\"=== ç•°ãªã‚‹å“è³ªãƒ¬ãƒ™ãƒ«ã§ã®æ¯”è¼ƒ ===\")\n",
        "\n",
        "# è¤‡æ•°ã®å“è³ªãƒ¬ãƒ™ãƒ«ã§åœ§ç¸®ã‚’è©¦è¡Œ\n",
        "quality_levels = [1, 3, 5, 8]  # ä½å“è³ªã‹ã‚‰é«˜å“è³ªã¾ã§\n",
        "results = []\n",
        "\n",
        "for q in quality_levels:\n",
        "    print(f\"å“è³ªãƒ¬ãƒ™ãƒ« {q} ã‚’ãƒ†ã‚¹ãƒˆä¸­...\")\n",
        "\n",
        "    # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
        "    temp_model = mbt2018(quality=q, pretrained=True, progress=False)\n",
        "    temp_model = temp_model.to(device)\n",
        "    temp_model.eval()\n",
        "\n",
        "    # ãƒ†ã‚¹ãƒˆç”»åƒã§åœ§ç¸®\n",
        "    with torch.no_grad():\n",
        "        temp_compressed = temp_model.compress(test_image)\n",
        "        temp_decompressed = temp_model.decompress(temp_compressed[\"strings\"], temp_compressed[\"shape\"])\n",
        "        temp_reconstructed = temp_decompressed[\"x_hat\"]\n",
        "\n",
        "    # å“è³ªè©•ä¾¡\n",
        "    temp_mse = torch.mean((test_image - temp_reconstructed) ** 2).item()\n",
        "    temp_psnr = -10 * torch.log10(torch.tensor(temp_mse)) if temp_mse > 0 else float('inf')\n",
        "    temp_size = len(temp_compressed['strings'][0])\n",
        "    temp_bpp = temp_size * 8 / (256 * 256)\n",
        "\n",
        "    results.append({\n",
        "        'quality': q,\n",
        "        'mse': temp_mse,\n",
        "        'psnr': temp_psnr,\n",
        "        'size': temp_size,\n",
        "        'bpp': temp_bpp\n",
        "    })\n",
        "\n",
        "# çµæœã®è¡¨ç¤º\n",
        "print(\"\\n=== å“è³ªãƒ¬ãƒ™ãƒ«æ¯”è¼ƒçµæœ ===\")\n",
        "print(\"å“è³ª | PSNR(dB) | ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º(bytes) | ãƒ“ãƒƒãƒˆ/ãƒ”ã‚¯ã‚»ãƒ«\")\n",
        "print(\"-\" * 55)\n",
        "for r in results:\n",
        "    print(f\"{r['quality']:^4} | {r['psnr']:^8.2f} | {r['size']:^17,} | {r['bpp']:^12.3f}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ è§£é‡ˆ:\")\n",
        "print(\"- å“è³ªãƒ¬ãƒ™ãƒ«ãŒé«˜ã„ã»ã©ã€PSNRã¯é«˜ãï¼ˆç”»è³ªè‰¯ï¼‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¯å¤§ãã„\")\n",
        "print(\"- å“è³ªãƒ¬ãƒ™ãƒ«ãŒä½ã„ã»ã©ã€PSNRã¯ä½ãï¼ˆç”»è³ªåŠ£ï¼‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¯å°ã•ã„\")\n",
        "print(\"- ç”¨é€”ã«å¿œã˜ã¦é©åˆ‡ãªå“è³ªãƒ¬ãƒ™ãƒ«ã‚’é¸æŠå¯èƒ½\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6hfmt0Kq1zF"
      },
      "outputs": [],
      "source": [
        "## ã¾ã¨ã‚\n",
        "\n",
        "### âœ… å®Ÿç¾ã§ããŸã“ã¨\n",
        "- **è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«**ã«ã‚ˆã‚‹å®Ÿéš›ã®ç”»åƒåœ§ç¸®ãƒ»å±•é–‹\n",
        "- **å“è³ªè©•ä¾¡**: PSNRã€åœ§ç¸®ç‡ã€ãƒ“ãƒƒãƒˆ/ãƒ”ã‚¯ã‚»ãƒ«ã®æ¸¬å®š\n",
        "- **è¦–è¦šçš„æ¯”è¼ƒ**: å…ƒç”»åƒã€å¾©å…ƒç”»åƒã€å·®åˆ†ç”»åƒã®è¡¨ç¤º\n",
        "- **å“è³ªãƒ¬ãƒ™ãƒ«èª¿æ•´**: 1-8ã®å“è³ªãƒ¬ãƒ™ãƒ«ã§ã®æ¯”è¼ƒ\n",
        "\n",
        "### ğŸ”¬ æŠ€è¡“çš„è©³ç´°\n",
        "- **è«–æ–‡**: \"Joint Autoregressive and Hierarchical Priors for Learned Image Compression\" (NeurIPS 2018)\n",
        "- **å®Ÿè£…**: CompressAI ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "- **ãƒ¢ãƒ‡ãƒ«**: mbt2018 (Minnen, BallÃ©, Toderici 2018)\n",
        "- **ç‰¹å¾´**: è‡ªå·±å›å¸°ãƒ»éšå±¤äº‹å‰åˆ†å¸ƒã«ã‚ˆã‚‹é«˜åŠ¹ç‡åœ§ç¸®\n",
        "\n",
        "### ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹çµæœ\n",
        "- **PSNR**: é€šå¸¸ 25-45 dBï¼ˆå“è³ªãƒ¬ãƒ™ãƒ«ã«ä¾å­˜ï¼‰\n",
        "- **åœ§ç¸®ç‡**: 10-100å€ï¼ˆå“è³ªãƒ¬ãƒ™ãƒ«ã«ä¾å­˜ï¼‰\n",
        "- **ãƒ“ãƒƒãƒˆ/ãƒ”ã‚¯ã‚»ãƒ«**: 0.1-2.0 bpp\n",
        "\n",
        "### ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
        "1. **ç•°ãªã‚‹ç”»åƒã§ã®å®Ÿé¨“**: è‡ªç„¶ç”»åƒã€ã‚¢ãƒ‹ãƒ¡ã€ãƒ†ã‚­ã‚¹ãƒˆãªã©\n",
        "2. **ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒ**: JPEGã€WebPã€ä»–ã®å­¦ç¿’ãƒ™ãƒ¼ã‚¹æ‰‹æ³•\n",
        "3. **ã‚«ã‚¹ã‚¿ãƒ ç”»åƒã§ã®è©¦è¡Œ**: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã®è¿½åŠ \n",
        "4. **å‹•ç”»åœ§ç¸®**: CompressAIã®å‹•ç”»åœ§ç¸®ãƒ¢ãƒ‡ãƒ«ã®è©¦è¡Œ\n",
        "\n",
        "### ğŸ’¡ å¿œç”¨å¯èƒ½æ€§\n",
        "- **Webã‚µãƒ¼ãƒ“ã‚¹**: ç”»åƒé…ä¿¡ã®é«˜åŠ¹ç‡åŒ–\n",
        "- **ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒª**: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ã®å‰Šæ¸›\n",
        "- **ç ”ç©¶**: ã‚ˆã‚Šé«˜æ€§èƒ½ãªåœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é–‹ç™ºåŸºç›¤\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
